{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple/\n",
      "Collecting git+https://github.com/makcedward/nlpaug.git\n",
      "  Cloning https://github.com/makcedward/nlpaug.git to /tmp/pip-req-build-ix0sntyp\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/makcedward/nlpaug.git /tmp/pip-req-build-ix0sntyp\n",
      "  Resolved https://github.com/makcedward/nlpaug.git to commit 23800cbb9632c7fc8c4a88d46f9c4ecf68a96299\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/lenovo/anaconda3/envs/pt/lib/python3.9/site-packages (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.2.0 in /home/lenovo/anaconda3/envs/pt/lib/python3.9/site-packages (from nlpaug==1.1.11) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.22.0 in /home/lenovo/anaconda3/envs/pt/lib/python3.9/site-packages (from nlpaug==1.1.11) (2.32.2)\n",
      "Collecting gdown>=4.0.0 (from nlpaug==1.1.11)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/54/70/e07c381e6488a77094f04c85c9caf1c8008cdc30778f7019bc52e5285ef0/gdown-5.2.0-py3-none-any.whl (18 kB)\n",
      "Collecting beautifulsoup4 (from gdown>=4.0.0->nlpaug==1.1.11)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/b1/fe/e8c672695b37eecc5cbf43e1d0638d88d66ba3a44c4d321c796f4e59167f/beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.9/147.9 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /home/lenovo/anaconda3/envs/pt/lib/python3.9/site-packages (from gdown>=4.0.0->nlpaug==1.1.11) (3.13.1)\n",
      "Requirement already satisfied: tqdm in /home/lenovo/anaconda3/envs/pt/lib/python3.9/site-packages (from gdown>=4.0.0->nlpaug==1.1.11) (4.66.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/lenovo/anaconda3/envs/pt/lib/python3.9/site-packages (from pandas>=1.2.0->nlpaug==1.1.11) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/lenovo/anaconda3/envs/pt/lib/python3.9/site-packages (from pandas>=1.2.0->nlpaug==1.1.11) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/lenovo/anaconda3/envs/pt/lib/python3.9/site-packages (from pandas>=1.2.0->nlpaug==1.1.11) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/lenovo/anaconda3/envs/pt/lib/python3.9/site-packages (from requests>=2.22.0->nlpaug==1.1.11) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/lenovo/anaconda3/envs/pt/lib/python3.9/site-packages (from requests>=2.22.0->nlpaug==1.1.11) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/lenovo/anaconda3/envs/pt/lib/python3.9/site-packages (from requests>=2.22.0->nlpaug==1.1.11) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/lenovo/anaconda3/envs/pt/lib/python3.9/site-packages (from requests>=2.22.0->nlpaug==1.1.11) (2024.6.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/lenovo/anaconda3/envs/pt/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas>=1.2.0->nlpaug==1.1.11) (1.16.0)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4->gdown>=4.0.0->nlpaug==1.1.11)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/d1/c2/fe97d779f3ef3b15f05c94a2f1e3d21732574ed441687474db9d342a7315/soupsieve-2.6-py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /home/lenovo/anaconda3/envs/pt/lib/python3.9/site-packages (from requests[socks]->gdown>=4.0.0->nlpaug==1.1.11) (1.7.1)\n",
      "Building wheels for collected packages: nlpaug\n",
      "  Building wheel for nlpaug (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for nlpaug: filename=nlpaug-1.1.11-py3-none-any.whl size=405883 sha256=0d08057e95da8834abe8bc52a3a55492baeab1b4a7508eb06ecd6351b965a7b4\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-dpgm8yj6/wheels/90/bc/37/e55b295d36cbaaaf8394dbd355d28e033e236d2bcc7cf77f3a\n",
      "Successfully built nlpaug\n",
      "Installing collected packages: soupsieve, beautifulsoup4, gdown, nlpaug\n",
      "Successfully installed beautifulsoup4-4.12.3 gdown-5.2.0 nlpaug-1.1.11 soupsieve-2.6\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy git+https://github.com/makcedward/nlpaug.git # 测试下来仅仅支持英文"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nlpaug.augmenter.char as nac\n",
    "import nlpaug.augmenter.word as naw\n",
    "import nlpaug.augmenter.sentence as nas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quick brown fox jumps over the lazy dog .\n"
     ]
    }
   ],
   "source": [
    "text = 'The quick brown fox jumps over the lazy dog .'\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The q t7ck growH fox H8mps over the lazy dog.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aug = nac.KeyboardAug()\n",
    "augmented_text = aug.augment(text)\n",
    "augmented_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'nlpaug.augmenter.char' has no attribute 'ContextualWordEmbsAug'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m中华人民共和国国歌\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m aug \u001b[38;5;241m=\u001b[39m \u001b[43mnac\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mContextualWordEmbsAug\u001b[49m()\n\u001b[1;32m      3\u001b[0m augmented_text \u001b[38;5;241m=\u001b[39m aug\u001b[38;5;241m.\u001b[39maugment(text)\n\u001b[1;32m      4\u001b[0m augmented_text\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'nlpaug.augmenter.char' has no attribute 'ContextualWordEmbsAug'"
     ]
    }
   ],
   "source": [
    "text = '中华人民共和国国歌'\n",
    "aug = nac.ContextualWordEmbsAug()\n",
    "augmented_text = aug.augment(text)\n",
    "augmented_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple/\n",
      "Collecting nlpcda\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/71/6c/a485fcaf573db12b5af5b4468883c0f67e37b36e7ea0ffb502ffef646a4e/nlpcda-2.5.8.tar.gz (527 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m527.2/527.2 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting jieba (from nlpcda)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/c6/cb/18eeb235f833b726522d7ebed54f2278ce28ba9438e3135ab0278d9792a2/jieba-0.42.1.tar.gz (19.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.2/19.2 MB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: requests in /home/lenovo/anaconda3/envs/pt/lib/python3.9/site-packages (from nlpcda) (2.32.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/lenovo/anaconda3/envs/pt/lib/python3.9/site-packages (from requests->nlpcda) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/lenovo/anaconda3/envs/pt/lib/python3.9/site-packages (from requests->nlpcda) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/lenovo/anaconda3/envs/pt/lib/python3.9/site-packages (from requests->nlpcda) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/lenovo/anaconda3/envs/pt/lib/python3.9/site-packages (from requests->nlpcda) (2024.6.2)\n",
      "Building wheels for collected packages: nlpcda, jieba\n",
      "  Building wheel for nlpcda (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for nlpcda: filename=nlpcda-2.5.8-py3-none-any.whl size=527646 sha256=155348be69ab52e9012a1d24bd0be4d616d31584d3585956155ad8f3025a1c4b\n",
      "  Stored in directory: /home/lenovo/.cache/pip/wheels/5b/79/67/bba004d2f97e1fa90b96b1893ea4abaa7f4504d347e9c18d1b\n",
      "  Building wheel for jieba (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for jieba: filename=jieba-0.42.1-py3-none-any.whl size=19314459 sha256=72d6bd2abd2feec9628274d92d80b173f32386a7f324c77083a0a6abb844b146\n",
      "  Stored in directory: /home/lenovo/.cache/pip/wheels/1a/76/68/b6d79c4db704bb18d54f6a73ab551185f4711f9730c0c15d97\n",
      "Successfully built nlpcda jieba\n",
      "Installing collected packages: jieba, nlpcda\n",
      "Successfully installed jieba-0.42.1 nlpcda-2.5.8\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/425776024/nlpcda  尝试使用中文文本增强\n",
    "!pip install nlpcda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load :/home/lenovo/anaconda3/envs/pt/lib/python3.9/site-packages/nlpcda/data/同义词.txt done\n",
      "smw:<nlpcda.tools.Similar_word.Similarword object at 0x7fed9f8877c0>\n",
      "随机同义词替换>>>>>>\n",
      "这是个实体：58同城；今天是2020年3月8日11:40，天气晴朗，天气很不错，空气很好，不差；这个nlpcad包，用于方便一键数据增强，可有效增强NLP模型的泛化性能、减少波动、抵抗对抗攻击\n",
      "这是个实体：58同城；今儿个是2020年3月8日11:40，天气晴朗，天气很对头，气氛很好，不差；者nlpcad包，用于便宜一键数码加强，可有效增强NLP模型的泛化性能、裁减波动、负隅顽抗对阵攻击\n",
      "这是个实业：58同城；今天是2020年3月8日11:40，天气晴朗，气象很不错，氛围很好，不差；这个nlpcad包，用以方便一键数三改一加强，可有效增高NLP范的泛化性能、回落忽左忽右、拒分庭抗礼掊击\n"
     ]
    }
   ],
   "source": [
    "# 随机同义词替换\n",
    "from nlpcda import Similarword\n",
    "\n",
    "test_str = '''这是个实体：58同城；今天是2020年3月8日11:40，天气晴朗，天气很不错，空气很好，不差；这个nlpcad包，用于方便一键数据增强，可有效增强NLP模型的泛化性能、减少波动、抵抗对抗攻击'''\n",
    "smw = Similarword(create_num=3, change_rate=0.9)\n",
    "print(f'smw:{smw}')\n",
    "rs1 = smw.replace(test_str)\n",
    "print('随机同义词替换>>>>>>')\n",
    "for s in rs1:\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load :/home/lenovo/anaconda3/envs/pt/lib/python3.9/site-packages/nlpcda/data/同音意字.txt done\n",
      "随机近义字替换>>>>>>\n",
      "这是个实体：58同城；今天是2020年3月8日11:40，天气晴朗，天气很不错，空气很好，不差；这个nlpcad包，用于方便一键数据增强，可有效增强NLP模型的泛化性能、减少波动、抵抗对抗攻击\n",
      "籷是嗝实体：58同城；金天是2020年3月8日11:40，胋欺晴浪，天噐很不错，空气很好，不差；这个nlpcad包，用于方邉勩键数据增强，可鱿效增强NLP模型德泛化性能、减少波动、糴抗对抗攻击\n",
      "者是个实体：58同琤；今天是2020年3矱8日11:40，天气晴朗，天气很不错，空气痕好，钸差；淛个nlpcad包，用謣方便一鑑数据甑强，可有俲增强NLP模洐淂杋桦杏能、减少帗动、抵犺对抗觥击\n"
     ]
    }
   ],
   "source": [
    "# 随机近义字替换\n",
    "from nlpcda import Homophone\n",
    "\n",
    "test_str = '''这是个实体：58同城；今天是2020年3月8日11:40，天气晴朗，天气很不错，空气很好，不差；这个nlpcad包，用于方便一键数据增强，可有效增强NLP模型的泛化性能、减少波动、抵抗对抗攻击'''\n",
    "\n",
    "smw = Homophone(create_num=3, change_rate=0.3)\n",
    "rs1 = smw.replace(test_str)\n",
    "\n",
    "print('随机近义字替换>>>>>>')\n",
    "for s in rs1:\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "随机字删除>>>>>>\n",
      "这是个实体：58同城；今天是2020年3月8日11:40，天气晴朗，天气很不错，空气很好，不差；这个nlpcad包，用于方便一键数据增强，可有效增强NLP模型的泛化性能、减少波动、抵抗对抗攻击\n",
      "是个实体58同城；今天是2020年3月8日11:40，天气晴朗，天气很不错，空气，不差；这个nlpcad包用于方便一键数据增强，可有效增强NLP模型泛化性能、减少波动、抵抗对抗\n",
      "个实体：58同城；今天是2020年3月8日11:40，天气晴朗天气很不错空气好，不差这个nlpcad用于方便一键数据增强，有效增强NLP模型泛化性能、减少波动、抵抗对抗\n"
     ]
    }
   ],
   "source": [
    "from nlpcda import RandomDeleteChar\n",
    "\n",
    "test_str = '''这是个实体：58同城；今天是2020年3月8日11:40，天气晴朗，天气很不错，空气很好，不差；这个nlpcad包，用于方便一键数据增强，可有效增强NLP模型的泛化性能、减少波动、抵抗对抗攻击'''\n",
    "\n",
    "smw = RandomDeleteChar(create_num=3, change_rate=0.3)\n",
    "rs1 = smw.replace(test_str)\n",
    "\n",
    "print('随机字删除>>>>>>')\n",
    "for s in rs1:\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
